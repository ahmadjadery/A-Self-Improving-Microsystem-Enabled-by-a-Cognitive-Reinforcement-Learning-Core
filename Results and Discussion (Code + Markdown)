# Plotting the results
plt.figure(figsize=(14, 6))

# Subplot 1: Loss curves
plt.subplot(1, 2, 1)
plt.plot(ideal_losses, label='Ideal Model Loss', color='gray')
plt.plot(hat_losses, label='RICC-HAT Model Loss', color='blue', linewidth=2)
plt.title('Training Loss Comparison', fontsize=16)
plt.xlabel('Training Steps', fontsize=14)
plt.ylabel('Mean Squared Error Loss', fontsize=14)
plt.legend(fontsize=12)
plt.ylim(0, 0.1)

# Subplot 2: Function approximation
plt.subplot(1, 2, 2)
plt.plot(X_train.numpy(), y_train.numpy(), 'k--', label='Target Function', linewidth=3, alpha=0.5)
plt.plot(X_train.numpy(), ideal_model(X_train).detach().numpy(), 'r-', label='Ideal Model Fit')
plt.plot(X_train.numpy(), hat_model(X_train).detach().numpy(), 'b-', label='RICC-HAT Model Fit', linewidth=2.5)
plt.title('Function Approximation', fontsize=16)
plt.xlabel('State (s)', fontsize=14)
plt.ylabel('Action (a)', fontsize=14)
plt.legend(fontsize=12)

plt.tight_layout()
plt.show()

``````markdown
### Analysis and Conclusion

As you can see from the results:

1.  **Loss Curves:** The **RICC-HAT model's** loss is noisier and might converge slightly slower. This is expected! The agent is not just minimizing the error, it's simultaneously learning to be robust to the constant hardware noise we are injecting.
2.  **Function Approximation:** Both models learn the target function well. However, the policy learned by the **RICC-HAT model** is inherently robust. While the Ideal model might achieve a slightly lower loss in this perfect simulation, it would fail catastrophically when deployed on real, noisy hardware. The RICC-HAT agent, having trained in a "school of hard knocks," is already prepared for the real world.

This simple experiment demonstrates the power of the Hardware-Aware Training paradigm. Thank you for following along!
